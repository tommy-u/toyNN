/* 
Very basic NN implementation. Feed forward & backprop SGD.
Draws on http://leenissen.dk/fann/wp/ and 
https://github.com/mnielsen/neural-networks-and-deep-learning.
*/
#include <stdio.h>
#include <stdlib.h>
#include <stdarg.h>
#include <string.h>
#include <time.h>
#include <math.h>
#include <random.h>
typedef unsigned int uint;

typedef struct {
  uint num_layers;
  /* Num neurons in each layer */
  uint *layers;

  /* Jagged 2d array containing bias values. Not needed for first layer. */
  double **biases;

  /* List of num_layers -1 many 2d rectangular arrays of connections
     between layer l and l-1. An inner loop over one of these 2d arrays
     iterates over the neurons in layer l-1. */
  double ***connections;
} Net;

Net * tnn_init_net(uint num_layers, uint *layers){
  /* Creates Net struct. Assumes fully connected. */
  uint i;
  double **biases;
  double ***connections;

  /* Allocate biases array. */
  biases = malloc( num_layers * sizeof(double *));
  if(biases == NULL){
    printf("allocation of biases in init_net failed \n");
    exit(1);
  }  
  
  /* Skip input layer. */
  for(i=0; i<num_layers-1; i++){
    biases[i] = malloc( layers[i+1] * sizeof(double));
    if(biases[i] == NULL){
      printf("allocation of biases[%u] in init_net failed \n",i);
      exit(1);
    }
  }
  //testing                                                         
  for(i=0; i<num_layers-1; i++){
  uint j;
  for(j=0; j<layers[i+1]; j++)
    biases[i][j] = j;
  }

  /* Allocate connections. */
  connections = malloc( (num_layers - 1 ) * sizeof(double * ) );
  if(connections == NULL){
    printf("allocation of connections in init_net failed \n");
    exit(1);
  }

  /* Each connection matrix. */
  for(i=0; i<num_layers - 1; i++){
    connections[i] = malloc( layers[i+1] * sizeof(double * ) );
    if(biases[i] == NULL){
      printf("allocation of connections[%u] in init_net failed \n",i);
      exit(1);
    }
    /* Each neuron in the i+1th layer. */
    uint j;
    for(j=0; j<layers[i+1]; j++){
      connections[i][j] = malloc ( layers[i] * sizeof(double) );
      if(connections[i][j] == 0){
	printf("allocation of connections[%u][%u] in init_net failed \n",i,j);
	exit(1);
      }
    }
  }

  /* Create, initialize Net. */
  Net *n = malloc( sizeof(Net) );
  n->num_layers = num_layers;
  n->layers = layers;
  n->biases = biases;
  n->connections = connections;
  return n;
}



void tnn_destroy_net(Net *n){
  /* Properly free all heap  memory. */
  uint i;

  /* Free bias values. -1 because none for input. */
  for(i=0; i<n->num_layers-1; i++)
    free(n->biases[i]);
  free(n->biases);

  /* Free Connections. */
  for(i=0; i<n->num_layers-1; i++){
    uint j;
    for(j=0; j<n->layers[i+1]; j++){
      free(n->connections[i][j]);
    }
    free(n->connections[i]);
  }

  free(n->connections);
  free(n);
}

double tnn_sigmoid(double z){
  /* Sigmoid Fn */
  return 1 / ( 1 + exp( -1 * z ) );
 }

double tnn_sigmoid_prime(double z){
  /* Derivative of Sigmoid */
  return tnn_sigmoid(z) * (1 - tnn_sigmoid(z));
}

double * tnn_feedforward(Net *n, double *input){
  /* i iterates over layers, j iterates over the output, 
     k iterates over the input.  */
  double *previous, *current;
  previous = input;
  
  uint i;
  /* Loop over connection matrices between layers. */
  for (i=0; i<n->num_layers-1; i++) {
    /* This will contain the activations. */
    current = malloc(n->layers[i+1] * sizeof(double) );
    /* Temporary storage for layer activation. */
    uint j;

    /* Loop over output neurons (of this layer). */
    for(j=0; j<n->layers[i+1]; j++){
      uint k;
      /* Loop over incoming connection signals. This is the dot 
	 product of the input vector and the weight matrix. */
      for(k=0; k<n->layers[i]; k++){
	current[j] += previous[k] * n->connections[i][j][k];
      }
      /* Add the bias term, this is the preactivation.  */
      current[j] += n->biases[i][j];
      /* This is the activation of the n->layers[i+1] neurons in
	 the i+1st layer. */
      current[j] = tnn_sigmoid(current[j]);
    }
    
    if(i!=0)
      free(previous);

    previous = current;
  }
  //current needs to be freed elsewhere. 
  return current; 
}

void tnn_print_net(Net *n){
  
  printf("----------------------------------------------\n");
  
  printf("layer counts in->out: ");
  uint i;
  for(i=0;i<n->num_layers;i++){
    printf("%u",n->layers[i]);
    if (i!=n->num_layers-1)
      printf(" - ");
  }
  
  printf("\n");
  
  printf("\nBIAS, values starting with first hidden layer -> output\n");
  for(i=0;i<n->num_layers-1;i++){
    if (i!=0)
      printf("\n");

    printf("layer %u:\n",i+1);
    uint j;
    for(j=0;j<n->layers[i+1];j++){
      printf("n: %u \t v: %.3f \n",j,n->biases[i][j]);
    }
  }
  
  printf("\nCONNECTIONS, count on incoming connection. \n");
  for(i=0;i<n->num_layers-1;i++){
    if (i!=0)
      printf("\n");

    printf("layer %u:\n",i+1);

    uint j;
    for(j=0;j<n->layers[i+1];j++){
      uint k=0;
      for(k=0;k<n->layers[i];k++){
	printf("o: %u i: %u\t%.3f\n",j,k,n->connections[i][j][k]);
      }
    }
  }

  printf("----------------------------------------------\n");
}

void tnn_init_connections(n){
  uint i;
  for(i=0;i<n->num_layers-1;i++){
    uint j;
    for(j=0;j<n->layers[i+1];j++){
      uint k;
      for(k=0;k<n->layers[i];k++){
        n->connections[i][j][k] =-1;
      }
    }
  }
}

int main(){
  uint a[3]= {2, 3, 1};
  double in[2] = {1, 1};
  
  Net *n = tnn_init_net(3, a); 

  uint i;
  for(i=0;i<n->num_layers-1;i++){
    uint j;
    for(j=0;j<n->layers[i+1];j++){
      uint k;
      for(k=0;k<n->layers[i];k++){
	n->connections[i][j][k] =-1;
      }
    }
  }
  
  
  
  for(i=0;i<n->num_layers-1;i++){
    uint j;
    for(j=0;j<n->layers[i+1];j++){
      n->biases[i][j] = 0;
    }
  }
  
  double *out = tnn_feedforward(n, in);
  printf("out vec: \n");
  for(i=0;i<n->layers[n->num_layers-1]; i++)
    printf("%.3f \n",out[i]);
  
  printf("%f ", tnn_sigmoid( -3 * tnn_sigmoid(-2)  ));

  //  tnn_print_net(n);
  free(out);
  tnn_destroy_net(n);
  printf("exiting gracefully \n");
  return 0;
}
